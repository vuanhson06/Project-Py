import argparse, os, joblib, json
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from scipy import sparse

#-----------------------------------------------------------------------------------------------------------------------------------------------

RANDOM_STATE = 42 # Äá»ƒ Ä‘áº£m báº£o má»—i láº§n cháº¡y code sáº½ giá»¯ á»•n Ä‘á»‹nh káº¿t quáº£ tÃ¡i láº­p, trÃ¡nh randomness cá»§a scikit-learn

#-----------------------------------------------------------------------------------------------------------------------------------------------

def load_data(train_path, test_path): # Táº£i dá»¯ liá»‡u
    train = pd.read_csv(train_path)
    test = pd.read_csv(test_path)
    label_map = {'ham':0, 'spam':1}
    y_train = train['label'].map(label_map).values # Láº¥y cá»™t Label trong Train rá»“i gáº¯n ham = 0 vÃ  spam = 1
    y_test = test['label'].map(label_map).values # Láº¥y cá»™t Label trong Test rá»“i gáº¯n ham = 0 vÃ  spam = 1
    X_train_text = train['text'].astype(str).tolist() # Láº¥y cá»™t tin nháº¯n trong train rá»“i chuyá»ƒn sang dáº¡ng str (astype: lÃ  1 lá»‡nh trong pd Ä‘á»ƒ chuyá»ƒn dáº¡ng)(tolist lÃ  chuyá»ƒn tá»« dáº¡ng series cá»§a pd sang list thÆ°á»ng)
    X_test_text  = test['text'].astype(str).tolist() # Láº¥y cá»™t tin nháº¯n trong test rá»“i chuyá»ƒn sang dáº¡ng str
    return X_train_text, y_train, X_test_text, y_test

#-----------------------------------------------------------------------------------------------------------------------------------------------

def load_vectorizer(vec_path): # Má»Ÿ file vector Ä‘Ã£ pickle hÃ³a vÃ  gáº¯n vÃ  biáº¿n vec
    vec = joblib.load(vec_path)
    return vec

#-----------------------------------------------------------------------------------------------------------------------------------------------

def to_csr(X): # HÃ m nÃ y chuyá»ƒn dá»¯ liá»‡u Ä‘áº§u vÃ o X thÃ nh dáº¡ng ma tráº­n thÆ°a (sparse matrix) â€” cá»¥ thá»ƒ lÃ  kiá»ƒu CSR (Compressed Sparse Row) | 2 main reasons: 1-Tiáº¿t kiá»‡m bá»™ nhá»›, 2-TÆ°Æ¡ng thÃ­ch scikit-learn
    # Äáº£m báº£o dáº¡ng csr_matrix cho NB/LR/SVM
    if sparse.issparse(X): # HÃ m Ä‘á»ƒ kiá»ƒm tra xem X cÃ³ pháº£i sparse matrix ko
        return X.tocsr() # Chuyá»ƒn X sang Ä‘á»‹nh dáº¡ng CSR (vÃ¬ X cÃ³ thá»ƒ lÃ  CSC,COO)
    X = np.asarray(X) # Náº¿u X khÃ´ng pháº£i sparse (tá»©c lÃ  máº£ng NumPy hoáº·c list),thÃ¬ chuyá»ƒn nÃ³ thÃ nh máº£ng NumPy Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»“ng nháº¥t kiá»ƒu dá»¯ liá»‡u
    return sparse.csr_matrix(X) # Chuyá»ƒn máº£ng NumPy Ä‘Ã³ sang dáº¡ng CSR matrix

#-----------------------------------------------------------------------------------------------------------------------------------------------

def evaluate(y_true, y_pred): # HÃ m nÃ y nháº­n hai Ä‘áº§u vÃ o: y_true: nhÃ£n tháº­t, y_pred: nhÃ£n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n. VÃ  tráº£ vá» 7 chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh
                              # Accuracy = (Sá»‘ dá»± Ä‘oÃ¡n Ä‘Ãºng)/(Tá»•ng sá»‘ máº«u): Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
                              # Precision: Äá»™ chÃ­nh xÃ¡c cá»§a dá»± Ä‘oÃ¡n 'spam' --> Äo má»©c Ä‘á»™ tin cáº­y cá»§a dá»± Ä‘oÃ¡n 'spam' --> pre cao thÃ¬ Ã­t bÃ¡o sai
                              # Recall: Trong táº¥t cáº£ cÃ¡c máº«u thá»±c sá»± lÃ  spam, cÃ³ bao nhiÃªu pháº§n trÄƒm Ä‘Æ°á»£c model phÃ¡t hiá»‡n Ä‘Ãºng --> Äo má»©c Ä‘á»™ nháº¡y cáº£m cá»§a model -) recall cao thÃ¬ Ã­t bá» sÃ³t spam
                              # f1-score: Trung hÃ²a giá»¯a 2 chá»‰ sá»‘ Pre vÃ  Recall 
    acc = accuracy_score(y_true, y_pred)
    p,r,f1,_ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0) # TÃ­nh cÃ¡c chá»‰ sá»‘ theo trung bÃ¬nh trá»ng sá»‘
    p_m,r_m,f1_m,_ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0) # TÃ­nh cÃ¡c chá»‰ sá»‘ theo trung bÃ¬nh Ä‘á»u
    # Zero_division=0: Náº¿u trong dá»¯ liá»‡u test cÃ³ trÆ°á»ng há»£p precision hoáº·c recall chia cho 0 (vÃ­ dá»¥: mÃ´ hÃ¬nh khÃ´ng dá»± Ä‘oÃ¡n sample nÃ o thuá»™c má»™t class), thÃ¬ gÃ¡n káº¿t quáº£ = 0 thay vÃ¬ bÃ¡o lá»—i.
    return {'accuracy':acc, 'precision_weighted':p, 'recall_weighted':r, 'f1_weighted':f1, 'precision_macro':p_m, 'recall_macro':r_m, 'f1_macro':f1_m}

#-----------------------------------------------------------------------------------------------------------------------------------------------

def grid_and_cv(model_name): # Nháº­n model vÃ  tráº£ vá» object GridSearchCV --> Chá»n ra bá»™ tham sá»‘ tá»‘t nháº¥t theo tiÃªu chÃ­ f1_weighted.
    if model_name == "nb": 
        model = MultinomialNB() 
        param_grid = {"alpha": [0.1, 0.5, 1.0, 2.0, 5.0]} # Há»‡ sá»‘ lÃ m mÆ°á»£t, TrÃ¡nh xÃ¡c suáº¥t báº±ng 0

    elif model_name == "lr":
        model = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced', solver='liblinear')
        # max_iter=2000: sá»‘ vÃ²ng láº·p tá»‘i Ä‘a Ä‘á»ƒ thuáº­t toÃ¡n há»™i tá»¥
        # n_jobs=-1: dÃ¹ng táº¥t cáº£ CPU Ä‘á»ƒ train nhanh
        # class_weight='balanced': cÃ¢n báº±ng trá»ng sá»‘ cho cÃ¡c lá»›p máº¥t cÃ¢n báº±ng
        # 'liblinear': Bá»™ giáº£i (optimizer) dÃ¹ng Ä‘á»ƒ tÃ¬m trá»ng sá»‘ wi
        param_grid = {"C": [0.1, 0.5, 1.0, 2.0, 5.0], "penalty": ["l1", "l2"]} 
        # LÆ°á»›i tham sá»‘ C Ä‘á»ƒ thá»­: nhá» â†’ má»m (cho phÃ©p vÃ i Ä‘iá»ƒm sai), lá»›n â†’ cá»©ng (cá»‘ gáº¯ng Ä‘Ãºng háº¿t)
        # Penalty: 'l1':Ã©p nhiá»u trá»ng sá»‘ vá» 0 â†’ loáº¡i bá» tá»« khÃ´ng quan trá»ng; 'l2':giá»¯ táº¥t cáº£ trá»ng sá»‘ nhá» vÃ  mÆ°á»£t

    elif model_name == "svm":
        model = LinearSVC(random_state=RANDOM_STATE, class_weight='balanced') # class_weight='balanced': cÃ¢n báº±ng trá»ng sá»‘ cho cÃ¡c lá»›p máº¥t cÃ¢n báº±ng
        param_grid = {"C": [0.1, 0.5, 1.0, 2.0, 5.0]} # LÆ°á»›i tham sá»‘ C Ä‘á»ƒ thá»­: nhá» â†’ má»m (cho phÃ©p vÃ i Ä‘iá»ƒm sai), lá»›n â†’ cá»©ng (cá»‘ gáº¯ng Ä‘Ãºng háº¿t)

    else:
        raise ValueError("model_name must be one of: nb, lr, svm")

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
    # n_splits=5: Chia táº­p train thÃ nh 5 pháº§n (5-fold CV).
    # shuffle=True: Trá»™n ngáº«u nhiÃªn dá»¯ liá»‡u trÆ°á»›c khi chia.
    gs = GridSearchCV(model, param_grid, scoring="f1_weighted", cv=cv, n_jobs=-1, verbose=1)
    # Chá»n ra bá»™ tham sá»‘ tá»‘t nháº¥t theo tiÃªu chÃ­ f1_weighted.
    return gs

#------------------------------------------------------------------------------------------------------------------------------------------------

def main(args):
    # 1) Load data & vectorizer
    X_train_text, y_train, X_test_text, y_test = load_data(args.train, args.test)
    vec = load_vectorizer(args.vectorizer)

    # 2) Vectorize
    X_train = to_csr(vec.transform(X_train_text))
    X_test  = to_csr(vec.transform(X_test_text))

    # 3) GridSearchCV
    gs = grid_and_cv(args.model)
    gs.fit(X_train, y_train) # type: ignore

    # 4) ÄÃ¡nh giÃ¡ trÃªn test
    y_pred = gs.best_estimator_.predict(X_test) # y_pred lÃ  máº£ng dá»± Ä‘oÃ¡n nhÃ£n (0 hoáº·c 1, tÆ°Æ¡ng á»©ng vá»›i ham/spam).
    # gs lÃ  Ä‘á»‘i tÆ°á»£ng GridSearchCV Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n xong trÃªn táº­p train.
    # best_estimator_ lÃ  mÃ´ hÃ¬nh tá»‘t nháº¥t sau khi GridSearch thá»­ háº¿t cÃ¡c tham sá»‘ (vÃ­ dá»¥: LR vá»›i C=1.0, penalty='l2').
    #.predict(X_test) â†’ cháº¡y mÃ´ hÃ¬nh Ä‘Ã³ trÃªn dá»¯ liá»‡u test (chÆ°a tá»«ng tháº¥y khi train).
    metrics = evaluate(y_test, y_pred)
    metrics["best_params"] = gs.best_params_ # Tham sá»‘ tá»‘t nháº¥t sau GridSearch
    metrics["model"] = args.model # Loáº¡i mÃ´ hÃ¬nh

    # 5) LÆ°u model & log
    os.makedirs(os.path.dirname(args.out_model), exist_ok=True) # Ä‘áº£m báº£o cÃ³ thÆ° má»¥c Ä‘á»ƒ ghi file mÃ´ hÃ¬nh.
    joblib.dump(gs.best_estimator_, args.out_model) # LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t

    os.makedirs(os.path.dirname(args.metrics_csv), exist_ok=True) # Äáº£m báº£o thÆ° má»¥c reports/ tá»“n táº¡i
    row = pd.DataFrame([metrics]) # Biáº¿n metrics (dict) Ä‘Æ°á»£c chuyá»ƒn thÃ nh 1 dÃ²ng DataFrame
    if os.path.exists(args.metrics_csv): # Náº¿u file káº¿t quáº£ tá»“n táº¡i
        row.to_csv(args.metrics_csv, mode='a', index=False, header=False) # Ghi thÃªm dÃ²ng má»›i
    else:
        row.to_csv(args.metrics_csv, index=False) # Náº¿u chÆ°a cÃ³ thÃ¬ táº¡o file má»›i vá»›i dÃ²ng tiÃªu Ä‘á»

    print(json.dumps(metrics, indent=2))

if __name__ == "__main__": # Äiá»ƒm báº¯t Ä‘áº§u chÆ°Æ¡ng trÃ¬nh khi file nÃ y Ä‘Æ°á»£c cháº¡y trá»±c tiáº¿p
    parser = argparse.ArgumentParser() # Táº¡o má»™t Ä‘á»‘i tÆ°á»£ng parser Ä‘á»ƒ Ä‘á»c command line arguments
    parser.add_argument("--model", choices=["nb","lr","svm"], required=False, help="Äiá»n tÃªn model hoáº·c Ä‘á»ƒ trá»‘ng Ä‘á»ƒ test táº¥t cáº£")
    # Äá»‹nh nghÄ©a 1 tham sá»‘ cÃ³ dÃ²ng lá»‡nh tÃ¹y chá»n:
        # choices=["nb","lr","svm"]: chá»‰ cháº¥p nháº­n 3 giÃ¡ trá»‹ "nb", "lr", hoáº·c "svm".
        # required=False: khÃ´ng báº¯t buá»™c pháº£i nháº­p (cÃ³ thá»ƒ bá» trá»‘ng).
        # help="...": mÃ´ táº£ sáº½ hiá»‡n ra khi cháº¡y python Step3.py -h.
    parser.add_argument("--train", default="data/processed/train.csv") # Tham sá»‘ --train dÃ¹ng Ä‘á»ƒ chá»‰ Ä‘á»‹nh file dá»¯ liá»‡u train.
    parser.add_argument("--test",  default="data/processed/test.csv") # Tham sá»‘ --test dÃ¹ng Ä‘á»ƒ chá»‰ Ä‘á»‹nh file dá»¯ liá»‡u test.
    parser.add_argument("--vectorizer", default="artifacts/vectorizer.pkl") # File chá»©a vectorizer Ä‘Ã£ Ä‘Æ°á»£c lÆ°u tá»« bÆ°á»›c trÆ°á»›c
    parser.add_argument("--out_model", default="artifacts/spam_model.pkl") # ÄÆ°á»ng dáº«n nÆ¡i sáº½ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t sau khi train.
    parser.add_argument("--metrics_csv", default="reports/metrics.csv") # File CSV nÆ¡i ghi láº¡i cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh (accuracy,   f1_weighted, precision, â€¦).
    args = parser.parse_args() #Äá»c toÃ n bá»™ tham sá»‘ dÃ²ng lá»‡nh ngÆ°á»i dÃ¹ng nháº­p khi cháº¡y chÆ°Æ¡ng trÃ¬nh,vÃ  gÃ³i láº¡i trong biáº¿n args

    if args.model: # Náº¿u Ä‘Ã£ chá»‰ Ä‘á»‹nh model tá»« dÃ²ng lá»‡nh, thÃ¬ chá»‰ cháº¡y model Ä‘Ã³
        main(args) # VD cháº¡y "python Step3.py --model nb" thÃ¬ chá»‰ cháº¡y NB

    else:
        print("No model specified, running nb / lr / svm sequentially...") 

        results = {}
        model_paths = {}  # lÆ°u Ä‘Æ°á»ng dáº«n tá»«ng model
        models = ["nb", "lr", "svm"]

        for m in models:
            print(f"\n--- Training model: {m.upper()} ---")
            args.model = m
            args.out_model = f"artifacts/{m}_model.pkl"   # ğŸ”¹ má»—i model lÆ°u riÃªng file
            main(args)

            # Sau khi main() cháº¡y xong, Ä‘á»c metrics.csv Ä‘á»ƒ láº¥y Ä‘iá»ƒm má»›i nháº¥t
            df = pd.read_csv(args.metrics_csv)
            last_row = df.iloc[-1]
            results[m] = last_row["f1_weighted"]
            model_paths[m] = args.out_model

        # --- Chá»n model tá»‘t nháº¥t ---
        best_model_name = max(results, key=results.get) #type:ignore
        best_score = results[best_model_name]
        best_model_path = model_paths[best_model_name]

        # --- Copy model tá»‘t nháº¥t thÃ nh spam_model.pkl ---
        import shutil
        shutil.copy(best_model_path, "artifacts/spam_model.pkl")
        print(f"\nâœ… Best model: {best_model_name.upper()} (f1_weighted = {best_score:.4f})")
        print(f"Copied {best_model_path} â†’ artifacts/spam_model.pkl (for API use)")

        # --- LÆ°u tÃ³m táº¯t káº¿t quáº£ ---
        summary = {
            "best_model": best_model_name,
            "best_score": best_score,
            "all_results": results
        }
        os.makedirs("reports", exist_ok=True)
        with open("reports/best_model_summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        print("\nğŸ“„ Saved to reports/best_model_summary.json")
